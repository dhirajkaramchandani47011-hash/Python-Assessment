{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\dhiraj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dhiraj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhiraj\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhiraj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhiraj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhiraj\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, soupsieve, idna, charset_normalizer, certifi, requests, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.14.3 certifi-2025.11.12 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 soupsieve-2.8.1 typing-extensions-4.15.0 urllib3-2.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fcc64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage fetched successfully\n",
      "                                               Quote           Author  \\\n",
      "0  “The world as we have created it is a process ...  Albert Einstein   \n",
      "1  “It is our choices, Harry, that show what we t...     J.K. Rowling   \n",
      "2  “There are only two ways to live your life. On...  Albert Einstein   \n",
      "3  “The person, be it gentleman or lady, who has ...      Jane Austen   \n",
      "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe   \n",
      "\n",
      "                                           Tags  \n",
      "0        change, deep-thoughts, thinking, world  \n",
      "1                            abilities, choices  \n",
      "2  inspirational, life, live, miracle, miracles  \n",
      "3              aliteracy, books, classic, humor  \n",
      "4                    be-yourself, inspirational  \n",
      "Data successfully saved to quotes_scraped.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the URL\n",
    "url = \"http://quotes.toscrape.com\"\n",
    "\n",
    "# Step 2: Send request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 3: Check if request is successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Webpage fetched successfully\")\n",
    "else:\n",
    "    print(\"Failed to retrieve webpage\")\n",
    "    exit()\n",
    "\n",
    "# Step 4: Create BeautifulSoup object\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Step 5: Find all quote blocks\n",
    "quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "\n",
    "# Step 6: Extract required data\n",
    "quotes_list = []\n",
    "\n",
    "for quote in quotes:\n",
    "    text = quote.find(\"span\", class_=\"text\").get_text()\n",
    "    author = quote.find(\"small\", class_=\"author\").get_text()\n",
    "    tags = [tag.get_text() for tag in quote.find_all(\"a\", class_=\"tag\")]\n",
    "\n",
    "    quotes_list.append({\n",
    "        \"Quote\": text,\n",
    "        \"Author\": author,\n",
    "        \"Tags\": \", \".join(tags)\n",
    "    })\n",
    "\n",
    "# Step 7: Convert to DataFrame\n",
    "df = pd.DataFrame(quotes_list)\n",
    "\n",
    "# Step 8: Display extracted data\n",
    "print(df.head())\n",
    "\n",
    "# Step 9: Save data to CSV file\n",
    "df.to_csv(\"quotes_scraped.csv\", index=False)\n",
    "\n",
    "print(\"Data successfully saved to quotes_scraped.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca8f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"quotes_scraped.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
